{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"classes = os.listdir(\"../input/train_data/train_data\")\nlen(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import DataLoader\n\ndata_dir = \"../input\"\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.RandomResizedCrop(224),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ColorJitter(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntest_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntrain_data = datasets.ImageFolder(data_dir+\"/train_data/train_data\", transform=train_transform)\ntest_data = datasets.ImageFolder(data_dir+\"/test_data/test_data\", transform=test_transform)\n\nprint(train_data)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=150, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=150)\n\nlen(trainloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize data\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata_iter = iter(testloader)\nimages, labels = data_iter.next()\n\nfig = plt.figure(figsize=(25, 5))\nfor idx in range(2):\n    ax = fig.add_subplot(1, 5, idx + 1, xticks=[], yticks=[])\n    # unnormolaize first\n    img = images[idx] / 2 + 0.5\n    npimg = img.numpy()\n    img = np.transpose(npimg, (1, 2, 0)) #transpose\n    ax.imshow(img, cmap='gray')\n    title = classes[labels[idx]] + f\"\\tNumber: {idx}\"\n    ax.set_title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.densenet161(pretrained=True)\nmodel.classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze parameters\nfor param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2208, out_features=2208),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=2208, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.3),\n  nn.Linear(in_features=1024, out_features=16),\n  nn.LogSoftmax(dim=1)  \n)\n    \nmodel.classifier = classifier\nmodel.classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n# turn this off\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\ndef train_model(model,\n                train_loader,\n                valid_loader,\n                n_epochs,\n                optimizer,\n                scheduler,\n                criterion,\n                name=\"model.pt\",\n                path=None):\n    # compare overfited\n    train_loss_data, valid_loss_data = [], []\n    # check for validation loss\n    valid_loss_min = np.Inf\n    # calculate time\n    since = time.time()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    for epoch in range(n_epochs):\n        print(\"Epoch: {}/{}\".format(epoch + 1, n_epochs))\n        # monitor training loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        total = 0\n        correct = 0\n        e_since = time.time()\n\n        ###################\n        # train the model #\n        ###################\n        model.train()  # prep model for training\n        scheduler.step()  # step up scheduler\n        for images, labels in train_loader:\n            # Move input and label tensors to the default device\n            images, labels = images.to(device), labels.to(device)\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            log_ps = model(images)\n            # calculate the loss\n            loss = criterion(log_ps, labels)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update running training loss\n            train_loss += loss.item() * images.size(0)\n\n        ######################\n        # validate the model #\n        ######################\n        print(\"\\t\\tGoing for validation\")\n        model.eval()  # prep model for evaluation\n        for data, target in valid_loader:\n            # Move input and label tensors to the default device\n            data, target = data.to(device), target.to(device)\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the loss\n            loss_p = criterion(output, target)\n            # update running validation loss\n            valid_loss += loss_p.item() * data.size(0)\n            # calculate accuracy\n            proba = torch.exp(output)\n            top_p, top_class = proba.topk(1, dim=1)\n            equals = top_class == target.view(*top_class.shape)\n\n            _, predicted = torch.max(output.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n        # print training/validation statistics\n        # calculate average loss over an epoch\n        train_loss = train_loss / len(train_loader.dataset)\n        valid_loss = valid_loss / len(valid_loader.dataset)\n\n        # calculate train loss and running loss\n        train_loss_data.append(train_loss * 100)\n        valid_loss_data.append(valid_loss * 100)\n\n        print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n              \"\\tValid Loss:{:.6f}..\".format(valid_loss),\n              \"\\tAccuracy: {:.4f}\".format(correct / total * 100))\n\n        # save model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('\\tValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n                valid_loss_min,\n                valid_loss))\n            torch.save(model.state_dict(), name)\n            valid_loss_min = valid_loss\n            # save to google drive\n            if path is not None:\n                torch.save(model.state_dict(), path)\n\n        # Time take for one epoch\n        time_elapsed = time.time() - e_since\n        print('\\tEpoch:{} completed in {:.0f}m {:.0f}s'.format(\n            epoch + 1, time_elapsed // 60, time_elapsed % 60))\n\n    # compare total time\n    time_elapsed = time.time() - since\n    print('Training completed in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n\n    # return the model\n    return [model, train_loss_data, valid_loss_data]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_epoch = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, train_loss, valid_loss = train_model(model, trainloader,\n          testloader, total_epoch, optimizer,scheduler, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('model.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_loss, label=\"Training loss\")\nplt.plot(valid_loss, label=\"validation loss\")\nplt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def testModel(model, loader, device, criterion):\n    \n    test_loss = 0\n    accuracy = 0\n\n    with torch.no_grad():\n        \n        model.eval()\n\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            logps = model.forward(inputs)\n            batch_loss = criterion(logps, labels)\n\n            test_loss += batch_loss.item()\n\n            # Calculate accuracy\n            ps = torch.exp(logps)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)\n            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\n    print(\"Test Loss:{:.6f}\".format(test_loss),\n          \"\\nAccuracy: {:.4f}\".format(accuracy / len(loader) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testModel(model, testloader, device, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test2(model, loader, device, criterion):\n    test_loss = 0.0\n    class_correct = list(0. for i in range(102))\n    class_total = list(0. for i in range(102))\n\n    with torch.no_grad():\n        model.eval()\n        # iterate over test data\n        for data, target in loader:\n            # move tensors to GPU if CUDA is available\n            data, target = data.to(device), target.to(device)\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update test loss\n            test_loss += loss.item() * data.size(0)\n            # convert output probabilities to predicted class\n            _, pred = torch.max(output, 1)\n            # compare predictions to true label\n            correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n            # calculate test accuracy for each object class\n            for i in range(len(target)):\n                label = target.data[i]\n                class_correct[label] += correct[i].item()\n                class_total[label] += 1\n\n    # average test loss\n    test_loss = test_loss / len(loader.dataset)\n    print('Test Loss: {:.6f}'.format(test_loss))\n\n    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n        100. * np.sum(class_correct) / np.sum(class_total),\n        np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2(model, testloader, device, criterion)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}