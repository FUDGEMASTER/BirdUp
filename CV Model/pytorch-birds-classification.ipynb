{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!tar -xvzf /kaggle/input/200-bird-species-with-11788-images/CUB_200_2011.tgz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.handlers import ModelCheckpoint, EarlyStopping\nfrom ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\nfrom ignite.contrib.handlers import ProgressBar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_loaders(data_dir, batch_size):\n  transform = transforms.Compose([transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor()])\n  all_data = datasets.ImageFolder(data_dir, transform=transform)\n  train_data_len = int(len(all_data)*0.75)\n  valid_data_len = int((len(all_data) - train_data_len)/2)\n  test_data_len = int(len(all_data) - train_data_len - valid_data_len)\n  train_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n  train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n  val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n  test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n  return ((train_loader, val_loader, test_loader), all_data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_loader, val_loader, test_loader), classes = get_data_loaders(\"CUB_200_2011/images/\", 64)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_loader))\nprint(len(val_loader))\nprint(len(test_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.densenet169(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.classifier.in_features) \nprint(model.classifier.out_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_inputs = model.classifier.in_features\nlast_layer = nn.Linear(n_inputs, len(classes))\nmodel.classifier = last_layer\nif torch.cuda.is_available():\n    model.cuda()\nprint(model.classifier.out_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_history = {'accuracy':[],'loss':[]}\nvalidation_history = {'accuracy':[],'loss':[]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\nevaluator = create_supervised_evaluator(model,\n                                        device=device,\n                                        metrics={\n                                            'accuracy': Accuracy(),\n                                            'loss': Loss(criterion),\n                                            'cm':ConfusionMatrix(len(classes))\n                                            })\n@trainer.on(Events.ITERATION_COMPLETED)\ndef log_a_dot(engine):\n    print(\".\",end=\"\")\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(trainer):\n    evaluator.run(train_loader)\n    metrics = evaluator.state.metrics\n    accuracy = metrics['accuracy']*100\n    loss = metrics['loss']\n    training_history['accuracy'].append(accuracy)\n    training_history['loss'].append(loss)\n    print()\n    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, accuracy, loss))\n    \n@trainer.on(Events.EPOCH_COMPLETED)   \ndef log_validation_results(trainer):\n    evaluator.run(val_loader)\n    metrics = evaluator.state.metrics\n    accuracy = metrics['accuracy']*100\n    loss = metrics['loss']\n    validation_history['accuracy'].append(accuracy)\n    validation_history['loss'].append(loss)\n    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, accuracy, loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.run(train_loader, max_epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0. for i in range(len(classes)))\nclass_total = list(0. for i in range(len(classes)))\n\nmodel.eval()\n\nfor data, target in test_loader:\n    if torch.cuda.is_available(): \n        data, target = data.cuda(), target.cuda()\n    output = model(data)\n    loss = criterion(output, target)\n    test_loss += loss.item()*data.size(0)\n    _, pred = torch.max(output, 1)    \n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n    if len(target) == 64:\n      for i in range(64):\n          label = target.data[i]\n          class_correct[label] += correct[i].item()\n          class_total[label] += 1\n\ntest_loss = test_loss/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom io import BytesIO\nimport requests","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def apply_test_transforms(inp):\n    out = transforms.functional.resize(inp, [224,224])\n    out = transforms.functional.to_tensor(out)\n    out = transforms.functional.normalize(out, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, filepath, show_img=False, url=False):\n    if url:\n        response = requests.get(filepath)\n        im = Image.open(BytesIO(response.content))\n    else:\n         im = Image.open(filepath)\n    if show_img:\n        plt.imshow(im)\n    im_as_tensor = apply_test_transforms(im)\n    minibatch = torch.stack([im_as_tensor])\n    if torch.cuda.is_available():\n        minibatch = minibatch.cuda()\n    pred = model(minibatch)\n    _, classnum = torch.max(pred, 1)\n    print(classnum)\n    return classes[classnum]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def formatText(string):\n    string = string[4:]\n    string = string.replace(\"-\", \" \")\n    return string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formatText(predict(model, \"https://www.audubon.org/sites/default/files/styles/hero_cover_bird_page/public/web_h_andy-morffew_flickr-creative-common-by-2.0_altamiraoriole_flickr-3-adult.jpg?itok=ad9rnLPN\", show_img=True, url=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formatText(predict(model, \"CUB_200_2011/images/080.Green_Kingfisher/Green_Kingfisher_0027_71048.jpg\", show_img=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif torch.cuda.is_available():\n    images = images.cuda()\n\n# get sample outputs\noutput = model(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(15, 10))\nfor idx in np.arange(10):\n    ax = fig.add_subplot(10, 2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx].cpu(), (1, 2, 0)))\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.randn(1, 3, 224, 224, requires_grad=False).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model.cpu(), example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traced_script_module.save(\"birds-classification.zip\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}